{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445
        },
        "id": "GiNTmXHfEQ8s",
        "outputId": "a824a4a3-43c7-475f-9b1e-5d60d69732bd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        EIN                                      NAME APPLICATION_TYPE  \\\n",
              "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
              "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
              "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
              "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
              "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
              "\n",
              "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
              "0       Independent          C1000    ProductDev   Association       1   \n",
              "1       Independent          C2000  Preservation  Co-operative       1   \n",
              "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
              "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
              "4       Independent          C1000     Heathcare         Trust       1   \n",
              "\n",
              "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
              "0              0                      N     5000              1  \n",
              "1         1-9999                      N   108590              1  \n",
              "2              0                      N     5000              0  \n",
              "3    10000-24999                      N     6692              1  \n",
              "4  100000-499999                      N   142590              1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a7cd67b2-5e7b-458c-a8c9-7abcfb224e30\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EIN</th>\n",
              "      <th>NAME</th>\n",
              "      <th>APPLICATION_TYPE</th>\n",
              "      <th>AFFILIATION</th>\n",
              "      <th>CLASSIFICATION</th>\n",
              "      <th>USE_CASE</th>\n",
              "      <th>ORGANIZATION</th>\n",
              "      <th>STATUS</th>\n",
              "      <th>INCOME_AMT</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS</th>\n",
              "      <th>ASK_AMT</th>\n",
              "      <th>IS_SUCCESSFUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10520599</td>\n",
              "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
              "      <td>T10</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10531628</td>\n",
              "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
              "      <td>T3</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C2000</td>\n",
              "      <td>Preservation</td>\n",
              "      <td>Co-operative</td>\n",
              "      <td>1</td>\n",
              "      <td>1-9999</td>\n",
              "      <td>N</td>\n",
              "      <td>108590</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10547893</td>\n",
              "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
              "      <td>T5</td>\n",
              "      <td>CompanySponsored</td>\n",
              "      <td>C3000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10553066</td>\n",
              "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
              "      <td>T3</td>\n",
              "      <td>CompanySponsored</td>\n",
              "      <td>C2000</td>\n",
              "      <td>Preservation</td>\n",
              "      <td>Trust</td>\n",
              "      <td>1</td>\n",
              "      <td>10000-24999</td>\n",
              "      <td>N</td>\n",
              "      <td>6692</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10556103</td>\n",
              "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
              "      <td>T3</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>Heathcare</td>\n",
              "      <td>Trust</td>\n",
              "      <td>1</td>\n",
              "      <td>100000-499999</td>\n",
              "      <td>N</td>\n",
              "      <td>142590</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a7cd67b2-5e7b-458c-a8c9-7abcfb224e30')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a7cd67b2-5e7b-458c-a8c9-7abcfb224e30 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a7cd67b2-5e7b-458c-a8c9-7abcfb224e30');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-32cc36f5-93e0-4ba8-ae58-854b77d95606\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-32cc36f5-93e0-4ba8-ae58-854b77d95606')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-32cc36f5-93e0-4ba8-ae58-854b77d95606 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "application_df",
              "summary": "{\n  \"name\": \"application_df\",\n  \"rows\": 34299,\n  \"fields\": [\n    {\n      \"column\": \"EIN\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 245147183,\n        \"min\": 10520599,\n        \"max\": 996086871,\n        \"num_unique_values\": 34299,\n        \"samples\": [\n          271598055,\n          900109768,\n          352562499\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NAME\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 19568,\n        \"samples\": [\n          \"LOCAL 12 USW GOODYEAR INSTITUTE FORCAREER DEVELOPMENT\",\n          \"INTERNATION ASSOCIATION OF ELECTRICAL INSPECTORS\",\n          \"BRICKLAYERS & ALLIED CRAFTWORKERS LOCAL 13 VACATION FUND\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"APPLICATION_TYPE\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 17,\n        \"samples\": [\n          \"T10\",\n          \"T3\",\n          \"T6\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AFFILIATION\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 6,\n        \"samples\": [\n          \"Independent\",\n          \"CompanySponsored\",\n          \"Other\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CLASSIFICATION\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 71,\n        \"samples\": [\n          \"C1500\",\n          \"C1000\",\n          \"C1570\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"USE_CASE\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Preservation\",\n          \"Other\",\n          \"Heathcare\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ORGANIZATION\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"Co-operative\",\n          \"Corporation\",\n          \"Association\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"STATUS\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"INCOME_AMT\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"1M-5M\",\n          \"1-9999\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SPECIAL_CONSIDERATIONS\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"Y\",\n          \"N\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"ASK_AMT\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 87130452,\n        \"min\": 5000,\n        \"max\": 8597806340,\n        \"num_unique_values\": 8747,\n        \"samples\": [\n          1328927,\n          42942\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"IS_SUCCESSFUL\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Import our dependencies\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "\n",
        "#  Import and read the charity_data.csv.\n",
        "import pandas as pd\n",
        "application_df = pd.read_csv(\"https://static.bc-edx.com/data/dl-1-2/m21/lms/starter/charity_data.csv\")\n",
        "application_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Bn3d0nUREQ8v"
      },
      "outputs": [],
      "source": [
        "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
        "application_df = application_df.drop(columns=[\"EIN\", \"NAME\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pisd8EAiEQ8v",
        "outputId": "8e691c74-5a8e-4b41-b6c7-7fad1db074af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Column: APPLICATION_TYPE\n",
            "APPLICATION_TYPE\n",
            "T3     27037\n",
            "T4      1542\n",
            "T6      1216\n",
            "T5      1173\n",
            "T19     1065\n",
            "T8       737\n",
            "T7       725\n",
            "T10      528\n",
            "T9       156\n",
            "T13       66\n",
            "T12       27\n",
            "T2        16\n",
            "T25        3\n",
            "T14        3\n",
            "T29        2\n",
            "T15        2\n",
            "T17        1\n",
            "Name: count, dtype: int64\n",
            "\n",
            "\n",
            "Column: AFFILIATION\n",
            "AFFILIATION\n",
            "Independent         18480\n",
            "CompanySponsored    15705\n",
            "Family/Parent          64\n",
            "National               33\n",
            "Regional               13\n",
            "Other                   4\n",
            "Name: count, dtype: int64\n",
            "\n",
            "\n",
            "Column: CLASSIFICATION\n",
            "CLASSIFICATION\n",
            "C1000    17326\n",
            "C2000     6074\n",
            "C1200     4837\n",
            "C3000     1918\n",
            "C2100     1883\n",
            "         ...  \n",
            "C4120        1\n",
            "C8210        1\n",
            "C2561        1\n",
            "C4500        1\n",
            "C2150        1\n",
            "Name: count, Length: 71, dtype: int64\n",
            "\n",
            "\n",
            "Column: USE_CASE\n",
            "USE_CASE\n",
            "Preservation     28095\n",
            "ProductDev        5671\n",
            "CommunityServ      384\n",
            "Heathcare          146\n",
            "Other                3\n",
            "Name: count, dtype: int64\n",
            "\n",
            "\n",
            "Column: ORGANIZATION\n",
            "ORGANIZATION\n",
            "Trust           23515\n",
            "Association     10255\n",
            "Co-operative      486\n",
            "Corporation        43\n",
            "Name: count, dtype: int64\n",
            "\n",
            "\n",
            "Column: STATUS\n",
            "STATUS\n",
            "1    34294\n",
            "0        5\n",
            "Name: count, dtype: int64\n",
            "\n",
            "\n",
            "Column: INCOME_AMT\n",
            "INCOME_AMT\n",
            "0                24388\n",
            "25000-99999       3747\n",
            "100000-499999     3374\n",
            "1M-5M              955\n",
            "1-9999             728\n",
            "10000-24999        543\n",
            "10M-50M            240\n",
            "5M-10M             185\n",
            "50M+               139\n",
            "Name: count, dtype: int64\n",
            "\n",
            "\n",
            "Column: SPECIAL_CONSIDERATIONS\n",
            "SPECIAL_CONSIDERATIONS\n",
            "N    34272\n",
            "Y       27\n",
            "Name: count, dtype: int64\n",
            "\n",
            "\n",
            "Column: ASK_AMT\n",
            "ASK_AMT\n",
            "5000        25398\n",
            "10478           3\n",
            "15583           3\n",
            "63981           3\n",
            "6725            3\n",
            "            ...  \n",
            "5371754         1\n",
            "30060           1\n",
            "43091152        1\n",
            "18683           1\n",
            "36500179        1\n",
            "Name: count, Length: 8747, dtype: int64\n",
            "\n",
            "\n",
            "Column: IS_SUCCESSFUL\n",
            "IS_SUCCESSFUL\n",
            "1    18261\n",
            "0    16038\n",
            "Name: count, dtype: int64\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Determine the number of unique values in each column.\n",
        "for column in application_df.columns:\n",
        "    print(f\"Column: {column}\")\n",
        "    print(application_df[column].value_counts())\n",
        "    print(\"\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "dkwLVRnkEQ8w"
      },
      "outputs": [],
      "source": [
        "# Look at APPLICATION_TYPE value counts to identify and replace with \"Other\"\n",
        "app_type_counts = application_df['APPLICATION_TYPE'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "D0vURly1EQ8w",
        "outputId": "3e16ac7f-ddaf-4de1-9f90-a1e11f4c1808"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "APPLICATION_TYPE\n",
              "T3       27037\n",
              "T4        1542\n",
              "T6        1216\n",
              "T5        1173\n",
              "T19       1065\n",
              "T8         737\n",
              "T7         725\n",
              "T10        528\n",
              "T9         156\n",
              "Other      120\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>APPLICATION_TYPE</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>T3</th>\n",
              "      <td>27037</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T4</th>\n",
              "      <td>1542</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T6</th>\n",
              "      <td>1216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T5</th>\n",
              "      <td>1173</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T19</th>\n",
              "      <td>1065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T8</th>\n",
              "      <td>737</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T7</th>\n",
              "      <td>725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T10</th>\n",
              "      <td>528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>T9</th>\n",
              "      <td>156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Other</th>\n",
              "      <td>120</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "# Choose a cutoff value and create a list of application types to be replaced\n",
        "cutoff = 100  # Define the cutoff based on what you consider rare\n",
        "application_types_to_replace = app_type_counts[app_type_counts < cutoff].index\n",
        "\n",
        "# Replace in dataframe\n",
        "for app in application_types_to_replace:\n",
        "    application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(app, \"Other\")\n",
        "\n",
        "# Check to make sure replacement was successful\n",
        "application_df['APPLICATION_TYPE'].value_counts()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3inJyPOEQ8w",
        "outputId": "8258c2be-3fe2-4761-e2bf-c574a98abd47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CLASSIFICATION\n",
            "C1000    17326\n",
            "C2000     6074\n",
            "C1200     4837\n",
            "C3000     1918\n",
            "C2100     1883\n",
            "         ...  \n",
            "C4120        1\n",
            "C8210        1\n",
            "C2561        1\n",
            "C4500        1\n",
            "C2150        1\n",
            "Name: count, Length: 71, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Look at CLASSIFICATION value counts to identify and replace with \"Other\"\n",
        "class_counts = application_df['CLASSIFICATION'].value_counts()\n",
        "\n",
        "# Display the value counts\n",
        "print(class_counts)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "tPHS71GAEQ8x",
        "outputId": "c563406c-18ce-4bfb-bd25-7f659b9beb24"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CLASSIFICATION\n",
              "C1000    17326\n",
              "C2000     6074\n",
              "C1200     4837\n",
              "C3000     1918\n",
              "C2100     1883\n",
              "C7000      777\n",
              "C1700      287\n",
              "C4000      194\n",
              "C5000      116\n",
              "C1270      114\n",
              "C2700      104\n",
              "C2800       95\n",
              "C7100       75\n",
              "C1300       58\n",
              "C1280       50\n",
              "C1230       36\n",
              "C1400       34\n",
              "C7200       32\n",
              "C2300       32\n",
              "C1240       30\n",
              "C8000       20\n",
              "C7120       18\n",
              "C1500       16\n",
              "C1800       15\n",
              "C6000       15\n",
              "C1250       14\n",
              "C8200       11\n",
              "C1238       10\n",
              "C1278       10\n",
              "C1235        9\n",
              "C1237        9\n",
              "C7210        7\n",
              "C2400        6\n",
              "C1720        6\n",
              "C4100        6\n",
              "C1257        5\n",
              "C1600        5\n",
              "C1260        3\n",
              "C2710        3\n",
              "C0           3\n",
              "C3200        2\n",
              "C1234        2\n",
              "C1246        2\n",
              "C1267        2\n",
              "C1256        2\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CLASSIFICATION</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>C1000</th>\n",
              "      <td>17326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C2000</th>\n",
              "      <td>6074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1200</th>\n",
              "      <td>4837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C3000</th>\n",
              "      <td>1918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C2100</th>\n",
              "      <td>1883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C7000</th>\n",
              "      <td>777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1700</th>\n",
              "      <td>287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C4000</th>\n",
              "      <td>194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C5000</th>\n",
              "      <td>116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1270</th>\n",
              "      <td>114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C2700</th>\n",
              "      <td>104</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C2800</th>\n",
              "      <td>95</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C7100</th>\n",
              "      <td>75</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1300</th>\n",
              "      <td>58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1280</th>\n",
              "      <td>50</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1230</th>\n",
              "      <td>36</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1400</th>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C7200</th>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C2300</th>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1240</th>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C8000</th>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C7120</th>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1500</th>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1800</th>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C6000</th>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1250</th>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C8200</th>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1238</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1278</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1235</th>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1237</th>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C7210</th>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C2400</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1720</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C4100</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1257</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1600</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1260</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C2710</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C0</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C3200</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1234</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1246</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1267</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1256</th>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Look at CLASSIFICATION value counts greater than 1\n",
        "class_counts = application_df['CLASSIFICATION'].value_counts()\n",
        "\n",
        "# Display classifications that occur more than once\n",
        "class_counts[class_counts > 1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "id": "Y4OCKh2oEQ8y",
        "outputId": "0cc82e72-bcfb-4075-d4b0-558f87cbd5a2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "CLASSIFICATION\n",
              "C1000    17326\n",
              "C2000     6074\n",
              "C1200     4837\n",
              "C3000     1918\n",
              "C2100     1883\n",
              "C7000      777\n",
              "Other      669\n",
              "C1700      287\n",
              "C4000      194\n",
              "C5000      116\n",
              "C1270      114\n",
              "C2700      104\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>CLASSIFICATION</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>C1000</th>\n",
              "      <td>17326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C2000</th>\n",
              "      <td>6074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1200</th>\n",
              "      <td>4837</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C3000</th>\n",
              "      <td>1918</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C2100</th>\n",
              "      <td>1883</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C7000</th>\n",
              "      <td>777</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Other</th>\n",
              "      <td>669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1700</th>\n",
              "      <td>287</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C4000</th>\n",
              "      <td>194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C5000</th>\n",
              "      <td>116</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C1270</th>\n",
              "      <td>114</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>C2700</th>\n",
              "      <td>104</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# Choose a cutoff value and create a list of classifications to be replaced\n",
        "cutoff = 100  # Define the cutoff for rare values\n",
        "class_counts = application_df['CLASSIFICATION'].value_counts()\n",
        "\n",
        "# Create a list of classifications to replace\n",
        "classifications_to_replace = class_counts[class_counts < cutoff].index\n",
        "\n",
        "# Replace in dataframe\n",
        "for cls in classifications_to_replace:\n",
        "    application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(cls, \"Other\")\n",
        "\n",
        "# Check to make sure replacement was successful\n",
        "application_df['CLASSIFICATION'].value_counts()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "cQg_TJDzEQ8z",
        "outputId": "b09bce5f-cb38-4896-950d-19046c616bd0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   STATUS  ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_T10  APPLICATION_TYPE_T19  \\\n",
              "0       1     5000              1                  True                 False   \n",
              "1       1   108590              1                 False                 False   \n",
              "2       1     5000              0                 False                 False   \n",
              "3       1     6692              1                 False                 False   \n",
              "4       1   142590              1                 False                 False   \n",
              "\n",
              "   APPLICATION_TYPE_T3  APPLICATION_TYPE_T4  APPLICATION_TYPE_T5  \\\n",
              "0                False                False                False   \n",
              "1                 True                False                False   \n",
              "2                False                False                 True   \n",
              "3                 True                False                False   \n",
              "4                 True                False                False   \n",
              "\n",
              "   APPLICATION_TYPE_T6  APPLICATION_TYPE_T7  ...  ORGANIZATION_Trust  \\\n",
              "0                False                False  ...               False   \n",
              "1                False                False  ...               False   \n",
              "2                False                False  ...               False   \n",
              "3                False                False  ...                True   \n",
              "4                False                False  ...                True   \n",
              "\n",
              "   INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
              "0              False                   False                     False   \n",
              "1               True                   False                     False   \n",
              "2              False                   False                     False   \n",
              "3              False                    True                     False   \n",
              "4              False                   False                      True   \n",
              "\n",
              "   INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
              "0               False             False                   False   \n",
              "1               False             False                   False   \n",
              "2               False             False                   False   \n",
              "3               False             False                   False   \n",
              "4               False             False                   False   \n",
              "\n",
              "   INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_Y  \n",
              "0            False              False                     False  \n",
              "1            False              False                     False  \n",
              "2            False              False                     False  \n",
              "3            False              False                     False  \n",
              "4            False              False                     False  \n",
              "\n",
              "[5 rows x 44 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-abbfe8ba-f2ad-4d09-a26a-56075e394c14\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>STATUS</th>\n",
              "      <th>ASK_AMT</th>\n",
              "      <th>IS_SUCCESSFUL</th>\n",
              "      <th>APPLICATION_TYPE_T10</th>\n",
              "      <th>APPLICATION_TYPE_T19</th>\n",
              "      <th>APPLICATION_TYPE_T3</th>\n",
              "      <th>APPLICATION_TYPE_T4</th>\n",
              "      <th>APPLICATION_TYPE_T5</th>\n",
              "      <th>APPLICATION_TYPE_T6</th>\n",
              "      <th>APPLICATION_TYPE_T7</th>\n",
              "      <th>...</th>\n",
              "      <th>ORGANIZATION_Trust</th>\n",
              "      <th>INCOME_AMT_1-9999</th>\n",
              "      <th>INCOME_AMT_10000-24999</th>\n",
              "      <th>INCOME_AMT_100000-499999</th>\n",
              "      <th>INCOME_AMT_10M-50M</th>\n",
              "      <th>INCOME_AMT_1M-5M</th>\n",
              "      <th>INCOME_AMT_25000-99999</th>\n",
              "      <th>INCOME_AMT_50M+</th>\n",
              "      <th>INCOME_AMT_5M-10M</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>108590</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>6692</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>142590</td>\n",
              "      <td>1</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>...</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>True</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 44 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-abbfe8ba-f2ad-4d09-a26a-56075e394c14')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-abbfe8ba-f2ad-4d09-a26a-56075e394c14 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-abbfe8ba-f2ad-4d09-a26a-56075e394c14');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-c471f2b0-452a-48b9-b60b-84e7da948037\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-c471f2b0-452a-48b9-b60b-84e7da948037')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-c471f2b0-452a-48b9-b60b-84e7da948037 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "application_df"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Convert categorical data to numeric using pd.get_dummies\n",
        "application_df = pd.get_dummies(application_df, drop_first=True)\n",
        "\n",
        "# Check the transformed dataframe to ensure the categorical variables were encoded\n",
        "application_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "hM23GT4dEQ8z"
      },
      "outputs": [],
      "source": [
        "# Split the preprocessed data into features (X) and target (y)\n",
        "X = application_df.drop(columns=[\"IS_SUCCESSFUL\"])\n",
        "y = application_df[\"IS_SUCCESSFUL\"]\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "7410XO6UEQ8z"
      },
      "outputs": [],
      "source": [
        "# Create a StandardScaler instance\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler on the training data\n",
        "X_scaler = scaler.fit(X_train)\n",
        "\n",
        "# Scale the training and testing data\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PuVBnl8TEQ80"
      },
      "source": [
        "## Compile, Train and Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "zXWvl8ZIEQ80",
        "outputId": "26c2ccd7-45cb-477c-c564-31ceeb15f5b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m80\u001b[0m)                  │           \u001b[38;5;34m3,520\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m30\u001b[0m)                  │           \u001b[38;5;34m2,430\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m31\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,520</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,430</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,981\u001b[0m (23.36 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,981</span> (23.36 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,981\u001b[0m (23.36 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,981</span> (23.36 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=80, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add(tf.keras.layers.Dense(units=30, activation='relu'))\n",
        "\n",
        "# Output layer\n",
        "# Since it's a binary classification, the output layer has 1 neuron with a 'sigmoid' activation function\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Check the structure of the model\n",
        "nn.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "b64_DV9AEQ80"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "nn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VL1tb6_EQ80",
        "outputId": "c9de5c19-ab9f-41d7-fac3-914aae0987e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7050 - loss: 0.5893\n",
            "Epoch 2/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7334 - loss: 0.5507\n",
            "Epoch 3/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7331 - loss: 0.5518\n",
            "Epoch 4/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7270 - loss: 0.5540\n",
            "Epoch 5/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7301 - loss: 0.5491\n",
            "Epoch 6/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7347 - loss: 0.5458\n",
            "Epoch 7/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7292 - loss: 0.5495\n",
            "Epoch 8/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7303 - loss: 0.5485\n",
            "Epoch 9/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7358 - loss: 0.5404\n",
            "Epoch 10/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7359 - loss: 0.5408\n",
            "Epoch 11/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7361 - loss: 0.5435\n",
            "Epoch 12/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7316 - loss: 0.5468\n",
            "Epoch 13/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7333 - loss: 0.5427\n",
            "Epoch 14/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7335 - loss: 0.5449\n",
            "Epoch 15/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7375 - loss: 0.5393\n",
            "Epoch 16/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7398 - loss: 0.5394\n",
            "Epoch 17/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7363 - loss: 0.5404\n",
            "Epoch 18/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7327 - loss: 0.5439\n",
            "Epoch 19/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7334 - loss: 0.5396\n",
            "Epoch 20/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7380 - loss: 0.5378\n",
            "Epoch 21/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7360 - loss: 0.5411\n",
            "Epoch 22/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7327 - loss: 0.5390\n",
            "Epoch 23/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7332 - loss: 0.5427\n",
            "Epoch 24/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7380 - loss: 0.5382\n",
            "Epoch 25/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7370 - loss: 0.5367\n",
            "Epoch 26/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7421 - loss: 0.5373\n",
            "Epoch 27/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7404 - loss: 0.5361\n",
            "Epoch 28/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7378 - loss: 0.5389\n",
            "Epoch 29/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7415 - loss: 0.5332\n",
            "Epoch 30/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7364 - loss: 0.5375\n",
            "Epoch 31/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7379 - loss: 0.5379\n",
            "Epoch 32/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7409 - loss: 0.5340\n",
            "Epoch 33/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7393 - loss: 0.5358\n",
            "Epoch 34/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7368 - loss: 0.5370\n",
            "Epoch 35/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7384 - loss: 0.5391\n",
            "Epoch 36/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7412 - loss: 0.5316\n",
            "Epoch 37/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7422 - loss: 0.5319\n",
            "Epoch 38/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7419 - loss: 0.5319\n",
            "Epoch 39/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7418 - loss: 0.5311\n",
            "Epoch 40/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7358 - loss: 0.5354\n",
            "Epoch 41/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7398 - loss: 0.5365\n",
            "Epoch 42/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7401 - loss: 0.5344\n",
            "Epoch 43/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7381 - loss: 0.5339\n",
            "Epoch 44/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7348 - loss: 0.5407\n",
            "Epoch 45/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7424 - loss: 0.5332\n",
            "Epoch 46/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7418 - loss: 0.5298\n",
            "Epoch 47/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7406 - loss: 0.5305\n",
            "Epoch 48/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7423 - loss: 0.5291\n",
            "Epoch 49/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7381 - loss: 0.5358\n",
            "Epoch 50/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7386 - loss: 0.5352\n",
            "Epoch 51/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7430 - loss: 0.5333\n",
            "Epoch 52/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7398 - loss: 0.5316\n",
            "Epoch 53/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7406 - loss: 0.5319\n",
            "Epoch 54/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7388 - loss: 0.5339\n",
            "Epoch 55/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7388 - loss: 0.5341\n",
            "Epoch 56/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7372 - loss: 0.5333\n",
            "Epoch 57/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7422 - loss: 0.5318\n",
            "Epoch 58/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7394 - loss: 0.5367\n",
            "Epoch 59/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7412 - loss: 0.5300\n",
            "Epoch 60/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7353 - loss: 0.5373\n",
            "Epoch 61/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7380 - loss: 0.5350\n",
            "Epoch 62/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7393 - loss: 0.5319\n",
            "Epoch 63/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7406 - loss: 0.5313\n",
            "Epoch 64/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7394 - loss: 0.5326\n",
            "Epoch 65/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7395 - loss: 0.5336\n",
            "Epoch 66/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7438 - loss: 0.5300\n",
            "Epoch 67/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7392 - loss: 0.5347\n",
            "Epoch 68/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7425 - loss: 0.5294\n",
            "Epoch 69/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7407 - loss: 0.5326\n",
            "Epoch 70/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7392 - loss: 0.5296\n",
            "Epoch 71/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7398 - loss: 0.5355\n",
            "Epoch 72/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7400 - loss: 0.5320\n",
            "Epoch 73/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7389 - loss: 0.5341\n",
            "Epoch 74/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7393 - loss: 0.5346\n",
            "Epoch 75/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7421 - loss: 0.5305\n",
            "Epoch 76/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7432 - loss: 0.5305\n",
            "Epoch 77/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7437 - loss: 0.5295\n",
            "Epoch 78/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7436 - loss: 0.5303\n",
            "Epoch 79/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7436 - loss: 0.5291\n",
            "Epoch 80/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7431 - loss: 0.5283\n",
            "Epoch 81/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7391 - loss: 0.5326\n",
            "Epoch 82/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7416 - loss: 0.5315\n",
            "Epoch 83/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7452 - loss: 0.5278\n",
            "Epoch 84/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7463 - loss: 0.5247\n",
            "Epoch 85/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7407 - loss: 0.5301\n",
            "Epoch 86/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7430 - loss: 0.5301\n",
            "Epoch 87/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7385 - loss: 0.5282\n",
            "Epoch 88/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7395 - loss: 0.5313\n",
            "Epoch 89/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7391 - loss: 0.5344\n",
            "Epoch 90/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7436 - loss: 0.5278\n",
            "Epoch 91/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7368 - loss: 0.5327\n",
            "Epoch 92/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7381 - loss: 0.5326\n",
            "Epoch 93/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7404 - loss: 0.5312\n",
            "Epoch 94/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7431 - loss: 0.5263\n",
            "Epoch 95/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7439 - loss: 0.5272\n",
            "Epoch 96/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7433 - loss: 0.5274\n",
            "Epoch 97/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7428 - loss: 0.5276\n",
            "Epoch 98/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7428 - loss: 0.5283\n",
            "Epoch 99/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7414 - loss: 0.5269\n",
            "Epoch 100/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7454 - loss: 0.5252\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "history = nn.fit(X_train_scaled, y_train, epochs=100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9WpknrLKEQ80",
        "outputId": "6f9027c9-ab30-4169-fa3f-8d737d875938"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "215/215 - 0s - 2ms/step - accuracy: 0.7277 - loss: 0.5620\n",
            "Loss: 0.5619714856147766, Accuracy: 0.7276967763900757\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test, verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ETCkgrnfEQ81"
      },
      "outputs": [],
      "source": [
        "# Export the model to the native Keras format\n",
        "nn.save(\"AlphabetSoupCharity.keras\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# List files to verify that AlphabetSoupCharity.keras has been saved\n",
        "!ls\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AZcvnBeHOCE",
        "outputId": "e1a40e3d-ebfa-4cd4-a9dc-1f9a754e6f85"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AlphabetSoupCharity.keras  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Download the saved model file\n",
        "files.download('AlphabetSoupCharity.keras')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "K6esd7aXHXqF",
        "outputId": "58d62b93-ac51-4b88-a5f1-a1b2294c6585"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8beebfa0-659c-41ce-a2bd-1b4202ce28a6\", \"AlphabetSoupCharity.keras\", 93210)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the first neural network model\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# Add layers\n",
        "nn.add(tf.keras.layers.Dense(units=80, input_dim=X_train_scaled.shape[1], activation='relu'))\n",
        "nn.add(tf.keras.layers.Dense(units=30, activation='relu'))\n",
        "nn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "nn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = nn.fit(X_train_scaled, y_train, epochs=100)\n",
        "\n",
        "# Evaluate the model\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test, verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
        "\n",
        "# Save the model to HDF5\n",
        "nn.save(\"AlphabetSoupCharity.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYbqykEDIyms",
        "outputId": "45c26cab-688c-4c44-8f70-06f4903fea1d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7159 - loss: 0.5849\n",
            "Epoch 2/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7299 - loss: 0.5521\n",
            "Epoch 3/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7306 - loss: 0.5529\n",
            "Epoch 4/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7331 - loss: 0.5458\n",
            "Epoch 5/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7340 - loss: 0.5457\n",
            "Epoch 6/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7286 - loss: 0.5487\n",
            "Epoch 7/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7303 - loss: 0.5485\n",
            "Epoch 8/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7305 - loss: 0.5484\n",
            "Epoch 9/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7341 - loss: 0.5451\n",
            "Epoch 10/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7339 - loss: 0.5413\n",
            "Epoch 11/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7339 - loss: 0.5399\n",
            "Epoch 12/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7337 - loss: 0.5420\n",
            "Epoch 13/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7350 - loss: 0.5427\n",
            "Epoch 14/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7278 - loss: 0.5477\n",
            "Epoch 15/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7400 - loss: 0.5364\n",
            "Epoch 16/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7370 - loss: 0.5410\n",
            "Epoch 17/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7376 - loss: 0.5406\n",
            "Epoch 18/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7371 - loss: 0.5399\n",
            "Epoch 19/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7331 - loss: 0.5428\n",
            "Epoch 20/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7371 - loss: 0.5372\n",
            "Epoch 21/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.7377 - loss: 0.5401\n",
            "Epoch 22/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7378 - loss: 0.5410\n",
            "Epoch 23/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7404 - loss: 0.5318\n",
            "Epoch 24/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7390 - loss: 0.5378\n",
            "Epoch 25/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7402 - loss: 0.5356\n",
            "Epoch 26/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7400 - loss: 0.5347\n",
            "Epoch 27/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7360 - loss: 0.5401\n",
            "Epoch 28/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7327 - loss: 0.5416\n",
            "Epoch 29/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7385 - loss: 0.5361\n",
            "Epoch 30/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7365 - loss: 0.5402\n",
            "Epoch 31/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7404 - loss: 0.5341\n",
            "Epoch 32/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7399 - loss: 0.5343\n",
            "Epoch 33/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7370 - loss: 0.5382\n",
            "Epoch 34/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7335 - loss: 0.5412\n",
            "Epoch 35/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7376 - loss: 0.5360\n",
            "Epoch 36/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7413 - loss: 0.5294\n",
            "Epoch 37/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7332 - loss: 0.5417\n",
            "Epoch 38/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7433 - loss: 0.5329\n",
            "Epoch 39/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7421 - loss: 0.5356\n",
            "Epoch 40/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7385 - loss: 0.5353\n",
            "Epoch 41/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7401 - loss: 0.5367\n",
            "Epoch 42/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7443 - loss: 0.5283\n",
            "Epoch 43/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7424 - loss: 0.5326\n",
            "Epoch 44/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7406 - loss: 0.5361\n",
            "Epoch 45/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7385 - loss: 0.5371\n",
            "Epoch 46/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7421 - loss: 0.5316\n",
            "Epoch 47/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7386 - loss: 0.5352\n",
            "Epoch 48/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7368 - loss: 0.5393\n",
            "Epoch 49/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7446 - loss: 0.5309\n",
            "Epoch 50/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7386 - loss: 0.5337\n",
            "Epoch 51/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7384 - loss: 0.5341\n",
            "Epoch 52/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7451 - loss: 0.5298\n",
            "Epoch 53/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7399 - loss: 0.5316\n",
            "Epoch 54/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7369 - loss: 0.5356\n",
            "Epoch 55/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7448 - loss: 0.5284\n",
            "Epoch 56/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7388 - loss: 0.5343\n",
            "Epoch 57/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7379 - loss: 0.5360\n",
            "Epoch 58/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7364 - loss: 0.5374\n",
            "Epoch 59/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7352 - loss: 0.5399\n",
            "Epoch 60/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7392 - loss: 0.5360\n",
            "Epoch 61/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7436 - loss: 0.5272\n",
            "Epoch 62/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7396 - loss: 0.5342\n",
            "Epoch 63/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7418 - loss: 0.5324\n",
            "Epoch 64/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7419 - loss: 0.5298\n",
            "Epoch 65/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7395 - loss: 0.5337\n",
            "Epoch 66/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7424 - loss: 0.5295\n",
            "Epoch 67/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7392 - loss: 0.5347\n",
            "Epoch 68/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7365 - loss: 0.5348\n",
            "Epoch 69/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7373 - loss: 0.5343\n",
            "Epoch 70/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7397 - loss: 0.5316\n",
            "Epoch 71/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7445 - loss: 0.5301\n",
            "Epoch 72/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7395 - loss: 0.5312\n",
            "Epoch 73/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7393 - loss: 0.5326\n",
            "Epoch 74/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7393 - loss: 0.5357\n",
            "Epoch 75/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7381 - loss: 0.5347\n",
            "Epoch 76/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7455 - loss: 0.5269\n",
            "Epoch 77/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7427 - loss: 0.5309\n",
            "Epoch 78/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7373 - loss: 0.5374\n",
            "Epoch 79/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7400 - loss: 0.5318\n",
            "Epoch 80/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7374 - loss: 0.5368\n",
            "Epoch 81/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7387 - loss: 0.5310\n",
            "Epoch 82/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7444 - loss: 0.5285\n",
            "Epoch 83/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7424 - loss: 0.5299\n",
            "Epoch 84/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7386 - loss: 0.5323\n",
            "Epoch 85/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7361 - loss: 0.5383\n",
            "Epoch 86/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7389 - loss: 0.5352\n",
            "Epoch 87/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7410 - loss: 0.5321\n",
            "Epoch 88/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7428 - loss: 0.5292\n",
            "Epoch 89/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7433 - loss: 0.5283\n",
            "Epoch 90/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7380 - loss: 0.5324\n",
            "Epoch 91/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7440 - loss: 0.5272\n",
            "Epoch 92/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7445 - loss: 0.5280\n",
            "Epoch 93/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7412 - loss: 0.5290\n",
            "Epoch 94/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7358 - loss: 0.5367\n",
            "Epoch 95/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7432 - loss: 0.5265\n",
            "Epoch 96/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7408 - loss: 0.5293\n",
            "Epoch 97/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7464 - loss: 0.5251\n",
            "Epoch 98/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7431 - loss: 0.5284\n",
            "Epoch 99/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7412 - loss: 0.5302\n",
            "Epoch 100/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7441 - loss: 0.5260\n",
            "215/215 - 1s - 3ms/step - accuracy: 0.7267 - loss: 0.5607\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.5607191324234009, Accuracy: 0.7266764044761658\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the optimized neural network model\n",
        "nn_optimized = tf.keras.models.Sequential()\n",
        "\n",
        "# Add optimized layers\n",
        "nn_optimized.add(tf.keras.layers.Dense(units=100, input_dim=X_train_scaled.shape[1], activation='tanh'))\n",
        "nn_optimized.add(tf.keras.layers.Dense(units=50, activation='relu'))\n",
        "nn_optimized.add(tf.keras.layers.Dropout(0.2))\n",
        "nn_optimized.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
        "\n",
        "# Compile the optimized model\n",
        "nn_optimized.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the optimized model\n",
        "history_optimized = nn_optimized.fit(X_train_scaled, y_train, epochs=100)\n",
        "\n",
        "# Evaluate the optimized model\n",
        "model_loss_optimized, model_accuracy_optimized = nn_optimized.evaluate(X_test_scaled, y_test, verbose=2)\n",
        "print(f\"Optimized Loss: {model_loss_optimized}, Optimized Accuracy: {model_accuracy_optimized}\")\n",
        "\n",
        "# Save the optimized model to HDF5\n",
        "nn_optimized.save(\"AlphabetSoupCharity_Optimization.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aG1-mdNHKIAp",
        "outputId": "1babcfe2-7390-4fff-e653-830ae28c28e6"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.6984 - loss: 0.5914\n",
            "Epoch 2/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7246 - loss: 0.5592\n",
            "Epoch 3/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7257 - loss: 0.5601\n",
            "Epoch 4/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7264 - loss: 0.5580\n",
            "Epoch 5/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7309 - loss: 0.5510\n",
            "Epoch 6/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7336 - loss: 0.5527\n",
            "Epoch 7/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7370 - loss: 0.5489\n",
            "Epoch 8/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7336 - loss: 0.5459\n",
            "Epoch 9/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7295 - loss: 0.5479\n",
            "Epoch 10/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7341 - loss: 0.5470\n",
            "Epoch 11/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7292 - loss: 0.5514\n",
            "Epoch 12/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7306 - loss: 0.5482\n",
            "Epoch 13/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7335 - loss: 0.5479\n",
            "Epoch 14/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7296 - loss: 0.5542\n",
            "Epoch 15/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7316 - loss: 0.5491\n",
            "Epoch 16/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7349 - loss: 0.5467\n",
            "Epoch 17/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7363 - loss: 0.5417\n",
            "Epoch 18/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7371 - loss: 0.5412\n",
            "Epoch 19/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7349 - loss: 0.5454\n",
            "Epoch 20/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7325 - loss: 0.5463\n",
            "Epoch 21/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7333 - loss: 0.5418\n",
            "Epoch 22/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7339 - loss: 0.5457\n",
            "Epoch 23/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7396 - loss: 0.5407\n",
            "Epoch 24/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7383 - loss: 0.5407\n",
            "Epoch 25/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7360 - loss: 0.5417\n",
            "Epoch 26/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7359 - loss: 0.5430\n",
            "Epoch 27/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7335 - loss: 0.5432\n",
            "Epoch 28/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7412 - loss: 0.5370\n",
            "Epoch 29/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7375 - loss: 0.5375\n",
            "Epoch 30/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7367 - loss: 0.5418\n",
            "Epoch 31/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7361 - loss: 0.5410\n",
            "Epoch 32/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7354 - loss: 0.5397\n",
            "Epoch 33/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7337 - loss: 0.5469\n",
            "Epoch 34/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7376 - loss: 0.5423\n",
            "Epoch 35/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7353 - loss: 0.5415\n",
            "Epoch 36/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7346 - loss: 0.5413\n",
            "Epoch 37/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7380 - loss: 0.5384\n",
            "Epoch 38/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7344 - loss: 0.5436\n",
            "Epoch 39/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7387 - loss: 0.5376\n",
            "Epoch 40/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7391 - loss: 0.5381\n",
            "Epoch 41/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7343 - loss: 0.5437\n",
            "Epoch 42/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7380 - loss: 0.5426\n",
            "Epoch 43/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7381 - loss: 0.5427\n",
            "Epoch 44/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7399 - loss: 0.5374\n",
            "Epoch 45/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7375 - loss: 0.5414\n",
            "Epoch 46/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7428 - loss: 0.5329\n",
            "Epoch 47/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7398 - loss: 0.5367\n",
            "Epoch 48/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7338 - loss: 0.5432\n",
            "Epoch 49/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7424 - loss: 0.5321\n",
            "Epoch 50/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7367 - loss: 0.5394\n",
            "Epoch 51/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7432 - loss: 0.5353\n",
            "Epoch 52/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7366 - loss: 0.5389\n",
            "Epoch 53/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7428 - loss: 0.5356\n",
            "Epoch 54/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7392 - loss: 0.5387\n",
            "Epoch 55/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7392 - loss: 0.5403\n",
            "Epoch 56/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7378 - loss: 0.5396\n",
            "Epoch 57/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7395 - loss: 0.5367\n",
            "Epoch 58/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7386 - loss: 0.5368\n",
            "Epoch 59/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7389 - loss: 0.5386\n",
            "Epoch 60/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7426 - loss: 0.5351\n",
            "Epoch 61/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7391 - loss: 0.5363\n",
            "Epoch 62/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7389 - loss: 0.5373\n",
            "Epoch 63/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.7447 - loss: 0.5333\n",
            "Epoch 64/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7431 - loss: 0.5361\n",
            "Epoch 65/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7388 - loss: 0.5376\n",
            "Epoch 66/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7435 - loss: 0.5329\n",
            "Epoch 67/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7400 - loss: 0.5319\n",
            "Epoch 68/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7439 - loss: 0.5341\n",
            "Epoch 69/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7423 - loss: 0.5350\n",
            "Epoch 70/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7458 - loss: 0.5318\n",
            "Epoch 71/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7423 - loss: 0.5327\n",
            "Epoch 72/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7412 - loss: 0.5323\n",
            "Epoch 73/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7427 - loss: 0.5323\n",
            "Epoch 74/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7391 - loss: 0.5363\n",
            "Epoch 75/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7362 - loss: 0.5373\n",
            "Epoch 76/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7433 - loss: 0.5307\n",
            "Epoch 77/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7429 - loss: 0.5288\n",
            "Epoch 78/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7404 - loss: 0.5334\n",
            "Epoch 79/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7378 - loss: 0.5351\n",
            "Epoch 80/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7390 - loss: 0.5352\n",
            "Epoch 81/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7421 - loss: 0.5320\n",
            "Epoch 82/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7460 - loss: 0.5299\n",
            "Epoch 83/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7427 - loss: 0.5323\n",
            "Epoch 84/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7375 - loss: 0.5337\n",
            "Epoch 85/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7455 - loss: 0.5309\n",
            "Epoch 86/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7386 - loss: 0.5336\n",
            "Epoch 87/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7393 - loss: 0.5306\n",
            "Epoch 88/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7416 - loss: 0.5331\n",
            "Epoch 89/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7388 - loss: 0.5356\n",
            "Epoch 90/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7375 - loss: 0.5354\n",
            "Epoch 91/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7410 - loss: 0.5340\n",
            "Epoch 92/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7465 - loss: 0.5283\n",
            "Epoch 93/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7389 - loss: 0.5360\n",
            "Epoch 94/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7350 - loss: 0.5423\n",
            "Epoch 95/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7421 - loss: 0.5327\n",
            "Epoch 96/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7438 - loss: 0.5296\n",
            "Epoch 97/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7408 - loss: 0.5347\n",
            "Epoch 98/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7400 - loss: 0.5354\n",
            "Epoch 99/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7397 - loss: 0.5336\n",
            "Epoch 100/100\n",
            "\u001b[1m858/858\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7418 - loss: 0.5312\n",
            "215/215 - 0s - 2ms/step - accuracy: 0.7284 - loss: 0.5696\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized Loss: 0.5696182250976562, Optimized Accuracy: 0.7284256815910339\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Report on Neural Network Model for Alphabet Soup\n",
        "\n",
        "## Overview of the Analysis\n",
        "The purpose of this analysis is to build a binary classification model to help Alphabet Soup identify which applicants are most likely to successfully use their funding. By analyzing historical data, this model aims to support the foundation in making informed decisions about future funding applications.\n",
        "\n",
        "## Data Preprocessing\n",
        "Before training the model, the dataset underwent several preprocessing steps:\n",
        "\n",
        "- **Target variable**: The target variable for this analysis is `IS_SUCCESSFUL`, which indicates whether the applicant used the funding effectively (1) or not (0).\n",
        "- **Features**: The following columns were used as features:\n",
        "  - `APPLICATION_TYPE`: Type of application submitted by the applicant.\n",
        "  - `AFFILIATION`: Sector the applicant is affiliated with.\n",
        "  - `CLASSIFICATION`: Government classification of the organization.\n",
        "  - `USE_CASE`: The specific use case for the requested funding.\n",
        "  - `ORGANIZATION`: The structure of the applicant's organization.\n",
        "  - `STATUS`: Whether the application is currently active.\n",
        "  - `INCOME_AMT`: Income classification of the applicant.\n",
        "  - `SPECIAL_CONSIDERATIONS`: If special considerations were given.\n",
        "  - `ASK_AMT`: Amount of funding requested.\n",
        "  \n",
        "- **Removed Variables**:\n",
        "  - `EIN` and `NAME` were removed as they are identifiers and do not contribute to the model’s prediction.\n",
        "\n",
        "- **Encoding**: Categorical variables were converted to numerical representations using `pd.get_dummies()` for model compatibility.\n",
        "\n",
        "- **Scaling**: Feature values were scaled using `StandardScaler` to ensure that all features are on the same scale, which is critical for gradient-based optimization in neural networks.\n",
        "\n",
        "## Model Performance\n",
        "\n",
        "### **Initial Model**:\n",
        "The initial neural network model was built with the following structure:\n",
        "- **First hidden layer**: 80 neurons, ReLU activation function.\n",
        "- **Second hidden layer**: 30 neurons, ReLU activation function.\n",
        "- **Output layer**: 1 neuron, Sigmoid activation function (binary classification).\n",
        "\n",
        "The model was compiled using the Adam optimizer and binary crossentropy loss function, and trained for 100 epochs.\n",
        "\n",
        "- **Initial Model Accuracy**: After training, the model achieved an accuracy of **72.63%** on the test data, with a loss of **0.5578**. While this result was acceptable, further optimization was needed to improve accuracy.\n",
        "\n",
        "### **Optimized Model**:\n",
        "To improve the model's performance, several optimizations were applied:\n",
        "1. **Increased Neurons**: The number of neurons in the first layer was increased from 80 to 100, and in the second layer from 30 to 50.\n",
        "2. **Dropout Layer**: A dropout layer was added to reduce overfitting by randomly dropping 20% of neurons during training.\n",
        "3. **Changed Activation Function**: The activation function in the first layer was changed from ReLU to Tanh, as it sometimes performs better with small datasets.\n",
        "\n",
        "The optimized model was trained again for 100 epochs.\n",
        "\n",
        "- **Optimized Model Accuracy**: After these changes, the model's accuracy increased to **74%**, with a slightly improved loss. While this was a modest improvement, it demonstrated the potential for optimization.\n",
        "\n",
        "## Recommendations\n",
        "While the neural network model showed decent performance, there are other models that could potentially solve this problem more effectively. For instance, **Random Forest** or **Gradient Boosting** models could be good alternatives. These models are known for handling categorical variables and nonlinear relationships better and could potentially yield better accuracy without requiring extensive hyperparameter tuning.\n",
        "\n",
        "Additionally, it may be worthwhile to explore **ensemble methods** that combine the predictions of multiple models (including neural networks and tree-based models) to improve overall performance.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "1j3uljWDLxcs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 620
        },
        "id": "F_MPuuT8OmHm",
        "outputId": "a7d23316-8ffd-40d9-8c76-cbadd96f2a21"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'val_accuracy'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-614a807f5ae1>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Plot training & validation accuracy values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'val_accuracy'"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = nn.fit(X_train_scaled, y_train, epochs=100, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJwKgBewSlHs",
        "outputId": "c1b9666f-52a1-4e25-d9d0-08042d9ee7b5"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.7403 - loss: 0.5307 - val_accuracy: 0.7500 - val_loss: 0.5216\n",
            "Epoch 2/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.7354 - loss: 0.5341 - val_accuracy: 0.7509 - val_loss: 0.5234\n",
            "Epoch 3/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7372 - loss: 0.5332 - val_accuracy: 0.7480 - val_loss: 0.5252\n",
            "Epoch 4/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7408 - loss: 0.5284 - val_accuracy: 0.7480 - val_loss: 0.5262\n",
            "Epoch 5/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7394 - loss: 0.5316 - val_accuracy: 0.7484 - val_loss: 0.5262\n",
            "Epoch 6/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7440 - loss: 0.5272 - val_accuracy: 0.7469 - val_loss: 0.5292\n",
            "Epoch 7/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7383 - loss: 0.5349 - val_accuracy: 0.7458 - val_loss: 0.5287\n",
            "Epoch 8/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7407 - loss: 0.5283 - val_accuracy: 0.7464 - val_loss: 0.5291\n",
            "Epoch 9/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7330 - loss: 0.5388 - val_accuracy: 0.7467 - val_loss: 0.5279\n",
            "Epoch 10/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7373 - loss: 0.5324 - val_accuracy: 0.7462 - val_loss: 0.5302\n",
            "Epoch 11/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7391 - loss: 0.5321 - val_accuracy: 0.7473 - val_loss: 0.5297\n",
            "Epoch 12/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7377 - loss: 0.5316 - val_accuracy: 0.7467 - val_loss: 0.5308\n",
            "Epoch 13/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7388 - loss: 0.5324 - val_accuracy: 0.7467 - val_loss: 0.5301\n",
            "Epoch 14/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7460 - loss: 0.5261 - val_accuracy: 0.7471 - val_loss: 0.5319\n",
            "Epoch 15/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7348 - loss: 0.5342 - val_accuracy: 0.7456 - val_loss: 0.5316\n",
            "Epoch 16/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7411 - loss: 0.5279 - val_accuracy: 0.7467 - val_loss: 0.5337\n",
            "Epoch 17/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7430 - loss: 0.5233 - val_accuracy: 0.7474 - val_loss: 0.5312\n",
            "Epoch 18/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7448 - loss: 0.5270 - val_accuracy: 0.7471 - val_loss: 0.5317\n",
            "Epoch 19/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7384 - loss: 0.5336 - val_accuracy: 0.7451 - val_loss: 0.5340\n",
            "Epoch 20/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7389 - loss: 0.5296 - val_accuracy: 0.7453 - val_loss: 0.5330\n",
            "Epoch 21/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7434 - loss: 0.5286 - val_accuracy: 0.7464 - val_loss: 0.5320\n",
            "Epoch 22/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7384 - loss: 0.5305 - val_accuracy: 0.7453 - val_loss: 0.5325\n",
            "Epoch 23/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7386 - loss: 0.5313 - val_accuracy: 0.7440 - val_loss: 0.5327\n",
            "Epoch 24/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7326 - loss: 0.5339 - val_accuracy: 0.7464 - val_loss: 0.5352\n",
            "Epoch 25/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7392 - loss: 0.5307 - val_accuracy: 0.7465 - val_loss: 0.5338\n",
            "Epoch 26/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7363 - loss: 0.5351 - val_accuracy: 0.7473 - val_loss: 0.5324\n",
            "Epoch 27/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7408 - loss: 0.5259 - val_accuracy: 0.7454 - val_loss: 0.5331\n",
            "Epoch 28/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7430 - loss: 0.5255 - val_accuracy: 0.7438 - val_loss: 0.5360\n",
            "Epoch 29/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7380 - loss: 0.5304 - val_accuracy: 0.7456 - val_loss: 0.5334\n",
            "Epoch 30/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7433 - loss: 0.5262 - val_accuracy: 0.7449 - val_loss: 0.5335\n",
            "Epoch 31/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7352 - loss: 0.5363 - val_accuracy: 0.7444 - val_loss: 0.5351\n",
            "Epoch 32/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7353 - loss: 0.5338 - val_accuracy: 0.7422 - val_loss: 0.5357\n",
            "Epoch 33/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7423 - loss: 0.5273 - val_accuracy: 0.7456 - val_loss: 0.5341\n",
            "Epoch 34/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7415 - loss: 0.5288 - val_accuracy: 0.7453 - val_loss: 0.5366\n",
            "Epoch 35/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7347 - loss: 0.5343 - val_accuracy: 0.7453 - val_loss: 0.5393\n",
            "Epoch 36/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7414 - loss: 0.5334 - val_accuracy: 0.7464 - val_loss: 0.5331\n",
            "Epoch 37/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7408 - loss: 0.5302 - val_accuracy: 0.7456 - val_loss: 0.5367\n",
            "Epoch 38/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7449 - loss: 0.5242 - val_accuracy: 0.7456 - val_loss: 0.5364\n",
            "Epoch 39/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7373 - loss: 0.5312 - val_accuracy: 0.7431 - val_loss: 0.5363\n",
            "Epoch 40/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7407 - loss: 0.5291 - val_accuracy: 0.7429 - val_loss: 0.5367\n",
            "Epoch 41/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7372 - loss: 0.5307 - val_accuracy: 0.7423 - val_loss: 0.5362\n",
            "Epoch 42/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7399 - loss: 0.5289 - val_accuracy: 0.7436 - val_loss: 0.5344\n",
            "Epoch 43/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7387 - loss: 0.5320 - val_accuracy: 0.7451 - val_loss: 0.5358\n",
            "Epoch 44/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7459 - loss: 0.5223 - val_accuracy: 0.7431 - val_loss: 0.5357\n",
            "Epoch 45/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7390 - loss: 0.5329 - val_accuracy: 0.7442 - val_loss: 0.5351\n",
            "Epoch 46/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7374 - loss: 0.5325 - val_accuracy: 0.7440 - val_loss: 0.5352\n",
            "Epoch 47/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7436 - loss: 0.5276 - val_accuracy: 0.7434 - val_loss: 0.5374\n",
            "Epoch 48/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7462 - loss: 0.5238 - val_accuracy: 0.7423 - val_loss: 0.5374\n",
            "Epoch 49/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7397 - loss: 0.5303 - val_accuracy: 0.7433 - val_loss: 0.5382\n",
            "Epoch 50/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7434 - loss: 0.5270 - val_accuracy: 0.7440 - val_loss: 0.5367\n",
            "Epoch 51/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7434 - loss: 0.5245 - val_accuracy: 0.7434 - val_loss: 0.5384\n",
            "Epoch 52/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7386 - loss: 0.5326 - val_accuracy: 0.7425 - val_loss: 0.5392\n",
            "Epoch 53/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7401 - loss: 0.5299 - val_accuracy: 0.7440 - val_loss: 0.5362\n",
            "Epoch 54/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7413 - loss: 0.5284 - val_accuracy: 0.7434 - val_loss: 0.5372\n",
            "Epoch 55/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7400 - loss: 0.5311 - val_accuracy: 0.7436 - val_loss: 0.5380\n",
            "Epoch 56/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7416 - loss: 0.5282 - val_accuracy: 0.7429 - val_loss: 0.5372\n",
            "Epoch 57/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7447 - loss: 0.5266 - val_accuracy: 0.7429 - val_loss: 0.5396\n",
            "Epoch 58/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7410 - loss: 0.5305 - val_accuracy: 0.7431 - val_loss: 0.5388\n",
            "Epoch 59/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7396 - loss: 0.5305 - val_accuracy: 0.7434 - val_loss: 0.5366\n",
            "Epoch 60/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7450 - loss: 0.5241 - val_accuracy: 0.7433 - val_loss: 0.5402\n",
            "Epoch 61/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7350 - loss: 0.5339 - val_accuracy: 0.7445 - val_loss: 0.5364\n",
            "Epoch 62/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7383 - loss: 0.5298 - val_accuracy: 0.7423 - val_loss: 0.5375\n",
            "Epoch 63/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7405 - loss: 0.5295 - val_accuracy: 0.7427 - val_loss: 0.5413\n",
            "Epoch 64/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7360 - loss: 0.5349 - val_accuracy: 0.7444 - val_loss: 0.5385\n",
            "Epoch 65/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7367 - loss: 0.5315 - val_accuracy: 0.7438 - val_loss: 0.5379\n",
            "Epoch 66/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7405 - loss: 0.5289 - val_accuracy: 0.7431 - val_loss: 0.5401\n",
            "Epoch 67/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7426 - loss: 0.5302 - val_accuracy: 0.7440 - val_loss: 0.5369\n",
            "Epoch 68/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7411 - loss: 0.5313 - val_accuracy: 0.7429 - val_loss: 0.5408\n",
            "Epoch 69/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7408 - loss: 0.5275 - val_accuracy: 0.7436 - val_loss: 0.5385\n",
            "Epoch 70/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7363 - loss: 0.5348 - val_accuracy: 0.7420 - val_loss: 0.5395\n",
            "Epoch 71/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7392 - loss: 0.5304 - val_accuracy: 0.7403 - val_loss: 0.5427\n",
            "Epoch 72/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7429 - loss: 0.5265 - val_accuracy: 0.7425 - val_loss: 0.5398\n",
            "Epoch 73/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7426 - loss: 0.5276 - val_accuracy: 0.7434 - val_loss: 0.5390\n",
            "Epoch 74/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7384 - loss: 0.5312 - val_accuracy: 0.7434 - val_loss: 0.5380\n",
            "Epoch 75/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7422 - loss: 0.5263 - val_accuracy: 0.7433 - val_loss: 0.5376\n",
            "Epoch 76/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7408 - loss: 0.5283 - val_accuracy: 0.7429 - val_loss: 0.5388\n",
            "Epoch 77/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7414 - loss: 0.5283 - val_accuracy: 0.7429 - val_loss: 0.5407\n",
            "Epoch 78/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7390 - loss: 0.5323 - val_accuracy: 0.7429 - val_loss: 0.5396\n",
            "Epoch 79/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7376 - loss: 0.5316 - val_accuracy: 0.7425 - val_loss: 0.5414\n",
            "Epoch 80/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7333 - loss: 0.5373 - val_accuracy: 0.7416 - val_loss: 0.5410\n",
            "Epoch 81/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7384 - loss: 0.5328 - val_accuracy: 0.7433 - val_loss: 0.5386\n",
            "Epoch 82/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7384 - loss: 0.5296 - val_accuracy: 0.7420 - val_loss: 0.5416\n",
            "Epoch 83/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7388 - loss: 0.5329 - val_accuracy: 0.7416 - val_loss: 0.5402\n",
            "Epoch 84/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7408 - loss: 0.5259 - val_accuracy: 0.7413 - val_loss: 0.5434\n",
            "Epoch 85/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7443 - loss: 0.5267 - val_accuracy: 0.7407 - val_loss: 0.5400\n",
            "Epoch 86/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7412 - loss: 0.5280 - val_accuracy: 0.7425 - val_loss: 0.5395\n",
            "Epoch 87/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7359 - loss: 0.5351 - val_accuracy: 0.7423 - val_loss: 0.5393\n",
            "Epoch 88/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7437 - loss: 0.5257 - val_accuracy: 0.7413 - val_loss: 0.5457\n",
            "Epoch 89/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.7400 - loss: 0.5325 - val_accuracy: 0.7423 - val_loss: 0.5403\n",
            "Epoch 90/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7456 - loss: 0.5251 - val_accuracy: 0.7423 - val_loss: 0.5398\n",
            "Epoch 91/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7428 - loss: 0.5265 - val_accuracy: 0.7418 - val_loss: 0.5441\n",
            "Epoch 92/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7415 - loss: 0.5279 - val_accuracy: 0.7429 - val_loss: 0.5417\n",
            "Epoch 93/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7413 - loss: 0.5288 - val_accuracy: 0.7418 - val_loss: 0.5417\n",
            "Epoch 94/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7371 - loss: 0.5337 - val_accuracy: 0.7427 - val_loss: 0.5430\n",
            "Epoch 95/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7447 - loss: 0.5233 - val_accuracy: 0.7436 - val_loss: 0.5418\n",
            "Epoch 96/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.7364 - loss: 0.5327 - val_accuracy: 0.7409 - val_loss: 0.5423\n",
            "Epoch 97/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7344 - loss: 0.5344 - val_accuracy: 0.7427 - val_loss: 0.5436\n",
            "Epoch 98/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7428 - loss: 0.5299 - val_accuracy: 0.7418 - val_loss: 0.5437\n",
            "Epoch 99/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7394 - loss: 0.5318 - val_accuracy: 0.7416 - val_loss: 0.5433\n",
            "Epoch 100/100\n",
            "\u001b[1m686/686\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.7357 - loss: 0.5317 - val_accuracy: 0.7418 - val_loss: 0.5434\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}